{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draco Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show you how to use Draco to solve a Machine Learning problem\n",
    "defined via a Target Times table.\n",
    "\n",
    "During the next steps we will:\n",
    "\n",
    "- Load demo target times and readings\n",
    "- Find available pipelines and load two of them as templates\n",
    "- Use Draco AutoML to select the best template and hyperparameters for our problem\n",
    "- Build and fit a Machine Learning pipeline based on the found template and hyperparameters\n",
    "- Make predictions using the fitted pipeline\n",
    "- Evaluate how good the predictions are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup the logging\n",
    "\n",
    "This step sets up logging in our environment to increase our visibility over\n",
    "the steps that Draco performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging;\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger().setLevel(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "\n",
    "The first step is to load the data that we are going to use.\n",
    "\n",
    "In order to use the demo data included in Draco, the `draco.demo.load_demo` function can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draco.demo import load_demo\n",
    "\n",
    "target_times, readings = load_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download some demo data from [Draco S3 demo Bucket](\n",
    "https://d3-ai-draco.s3.amazonaws.com/index.html) and load it as\n",
    "the necessary `target_times` and `readings` tables.\n",
    "\n",
    "The exact format of these tables is described in the Draco README and docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id cutoff_time  target\n",
       "0       T001  2013-01-12       0\n",
       "1       T001  2013-01-13       0\n",
       "2       T001  2013-01-14       0\n",
       "3       T001  2013-01-15       1\n",
       "4       T001  2013-01-16       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id             object\n",
       "cutoff_time    datetime64[ns]\n",
       "target                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>S01</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>S02</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>S03</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>S04</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>S05</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id signal_id  timestamp  value\n",
       "0       T001       S01 2013-01-10  323.0\n",
       "1       T001       S02 2013-01-10  320.0\n",
       "2       T001       S03 2013-01-10  284.0\n",
       "3       T001       S04 2013-01-10  348.0\n",
       "4       T001       S05 2013-01-10  273.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313540, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id            object\n",
       "signal_id             object\n",
       "timestamp     datetime64[ns]\n",
       "value                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your own Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you want to load your own dataset, all you have to do is load the\n",
    "`target_times` and `readings` tables as `pandas.DataFrame` objects.\n",
    "\n",
    "Make sure to parse the corresponding datetime fields!\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "target_times = pd.read_csv('path/to/your/target_times.csv', parse_dates=['cutoff_time'])\n",
    "readings = pd.read_csv('path/to/your/readings.csv', parse_dates=['timestamp'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data\n",
    "\n",
    "Once we have loaded the `target_times` and before proceeding to training any Machine Learning\n",
    "Pipeline, we will have split them in 2 partitions for training and testing.\n",
    "\n",
    "In this case, we will split them using the [train_test_split function from scikit-learn](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html),\n",
    "but it can be done with any other suitable tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(target_times, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding the available Templates\n",
    "\n",
    "The next step will be to select a collection of templates from the ones\n",
    "available in Draco.\n",
    "\n",
    "For this, we can use the `draco.get_pipelines` function, which will\n",
    "return us the list of all the available MLBlocks pipelines found in the\n",
    "Draco system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dummy',\n",
       " 'dfs_xgb_prob_with_unstack',\n",
       " 'dfs_xgb_with_normalization',\n",
       " 'dfs_xgb',\n",
       " 'dfs_xgb_with_unstack',\n",
       " 'dfs_xgb_prob_with_unstack_normalization',\n",
       " 'dfs_xgb_with_unstack_normalization',\n",
       " 'dfs_xgb_prob_with_double_normalization',\n",
       " 'dfs_xgb_with_double_normalization',\n",
       " 'lstm_regressor_with_unstack',\n",
       " 'lstm_regressor',\n",
       " 'double_lstm_prob_with_unstack',\n",
       " 'double_lstm_prob',\n",
       " 'double_lstm',\n",
       " 'double_lstm_with_unstack',\n",
       " 'lstm_prob_with_unstack',\n",
       " 'lstm_with_unstack',\n",
       " 'lstm_prob',\n",
       " 'lstm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from draco import get_pipelines\n",
    "\n",
    "get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can pass a string to select the pipelines that contain it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_regressor_with_unstack',\n",
       " 'lstm_regressor',\n",
       " 'double_lstm_prob_with_unstack',\n",
       " 'double_lstm_prob',\n",
       " 'double_lstm',\n",
       " 'double_lstm_with_unstack',\n",
       " 'lstm_prob_with_unstack',\n",
       " 'lstm_with_unstack',\n",
       " 'lstm_prob',\n",
       " 'lstm']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pipelines('lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can pass the keyword `path=True` to obtain a dictionary containing\n",
    "also the path to the pipelines instead of only the list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm_regressor_with_unstack': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm_regressor/lstm_regressor_with_unstack.json',\n",
       " 'lstm_regressor': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm_regressor/lstm_regressor.json',\n",
       " 'double_lstm_prob_with_unstack': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/double_lstm/double_lstm_prob_with_unstack.json',\n",
       " 'double_lstm_prob': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/double_lstm/double_lstm_prob.json',\n",
       " 'double_lstm': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/double_lstm/double_lstm.json',\n",
       " 'double_lstm_with_unstack': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/double_lstm/double_lstm_with_unstack.json',\n",
       " 'lstm_prob_with_unstack': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm/lstm_prob_with_unstack.json',\n",
       " 'lstm_with_unstack': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm/lstm_with_unstack.json',\n",
       " 'lstm_prob': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm/lstm_prob.json',\n",
       " 'lstm': '/Users/sarah/opt/anaconda3/envs/draco-mlstars/lib/python3.7/site-packages/draco/pipelines/lstm/lstm.json'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pipelines('lstm', path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this tutorial, we will select and use the templates\n",
    "`lstm_with_unstack` and\n",
    "`double_lstm_with_unstack`.\n",
    "\n",
    "The `lstm_with_unstack` template contains the following steps:\n",
    "\n",
    "- Resample the data using a 10 minute average aggregation\n",
    "- Unstack the data by signal, so each signal is in a different column\n",
    "- Scale the data between `[-1, 1]` using MinMaxScaler\n",
    "- Create training windows from readings based on the target_times cutoff times\n",
    "- Apply an LSTM Classifier\n",
    "\n",
    "And the `double_lstm_with_unstack` template contains the above steps but with two lstm layers instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'lstm_with_unstack', \n",
    "    'double_lstm_with_unstack'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding the best Pipeline\n",
    "\n",
    "Once we have loaded the data, we create a **DracoPipeline** instance by passing:\n",
    "\n",
    "* `templates (string or list)`: the name of a template, the path to a template json file or\n",
    "a list that can combine both of them.\n",
    "* `metric (string or function)`: The name of the metric to use or a metric function to use.\n",
    "* `cost (bool)`: Whether the metric is a cost function to be minimized or a score to be maximized.\n",
    "\n",
    "Optionally, we can also pass defails about the cross validation configuration:\n",
    "\n",
    "* `stratify`\n",
    "* `cv_splits`\n",
    "* `shuffle`\n",
    "* `random_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draco.pipeline import DracoPipeline\n",
    "\n",
    "pipeline = DracoPipeline(templates, metric='f1', cv_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the pipeline, we can find which template and which combination of hyperparameters works best for our data by calling the `tune` method of our pipeline, passing its `target_times` and `readings` variables.\n",
    "This method will return a `BTBSession` session that will:\n",
    "- Select and tune templates.\n",
    "- If a template or hyperparameters that get a higher score than the previous one is found, automatically update our pipeline so that it uses that template with those hyperparameters.\n",
    "- Remove templates that don't work with the given data and focus on tuning only the ones that do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = pipeline.tune(target_times, readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our `session` we can call it's method `run` with the amount of\n",
    "tuning iterations that we want to perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:btb.session:Obtaining default configuration for lstm_with_unstack\n",
      "2023-02-27 13:24:14.528911: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-02-27 13:24:14.610510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe9ac63ca30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-27 13:24:14.610531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:draco.pipeline:New configuration found:\n",
      "  Template: lstm_with_unstack \n",
      "    Hyperparameters: \n",
      "      ('sklearn.impute.SimpleImputer#1', 'strategy'): mean\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 80\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dropout_1_rate'): 0.3\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 80\n",
      "INFO:btb.session:New optimal found: lstm_with_unstack - 0.5836437904668181\n",
      "INFO:btb.session:Obtaining default configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n",
      "INFO:draco.pipeline:New configuration found:\n",
      "  Template: lstm_with_unstack \n",
      "    Hyperparameters: \n",
      "      ('sklearn.impute.SimpleImputer#1', 'strategy'): mean\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 343\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dropout_1_rate'): 0.01904463205949069\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 218\n",
      "INFO:btb.session:New optimal found: lstm_with_unstack - 0.6144588856166879\n",
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'b67b5786315b71a0031050a4a65e588b',\n",
       " 'name': 'lstm_with_unstack',\n",
       " 'config': {('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 343,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1',\n",
       "   'dropout_1_rate'): 0.01904463205949069,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 218},\n",
       " 'score': 0.6144588856166879}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this is done, the `best_proposal` will be printed out. We can access it anytime\n",
    "using `session.best_proposal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'b67b5786315b71a0031050a4a65e588b',\n",
       " 'name': 'lstm_with_unstack',\n",
       " 'config': {('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 343,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1',\n",
       "   'dropout_1_rate'): 0.01904463205949069,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 218},\n",
       " 'score': 0.6144588856166879}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.best_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the new hyperparameters are already set by calling `get_hyperparameters` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 343,\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1',\n",
       "  'dropout_1_rate'): 0.01904463205949069,\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 218}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the template name that is used to generate the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lstm_with_unstack'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.template_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can  also see the obtained cross validation score by looking at the `cv_score` attribute of the\n",
    "`pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6144588856166879"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If the score is not good enough, we can call the `run` method of the `session` again,\n",
    "specifying the amount of iterations, and this will resume its tuning process continuing from\n",
    "the previous results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n",
      "INFO:draco.pipeline:New configuration found:\n",
      "  Template: lstm_with_unstack \n",
      "    Hyperparameters: \n",
      "      ('sklearn.impute.SimpleImputer#1', 'strategy'): median\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 369\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dropout_1_rate'): 0.40028004355436897\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 317\n",
      "INFO:btb.session:New optimal found: lstm_with_unstack - 0.6236073368594607\n",
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n",
      "INFO:draco.pipeline:New configuration found:\n",
      "  Template: lstm_with_unstack \n",
      "    Hyperparameters: \n",
      "      ('sklearn.impute.SimpleImputer#1', 'strategy'): constant\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 69\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dropout_1_rate'): 0.2787263732968778\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 470\n",
      "INFO:btb.session:New optimal found: lstm_with_unstack - 0.6255876068376068\n",
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n",
      "INFO:draco.pipeline:New configuration found:\n",
      "  Template: lstm_with_unstack \n",
      "    Hyperparameters: \n",
      "      ('sklearn.impute.SimpleImputer#1', 'strategy'): constant\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 102\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dropout_1_rate'): 0.29143210730762764\n",
      "      ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 425\n",
      "INFO:btb.session:New optimal found: lstm_with_unstack - 0.6567251461988304\n",
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for double_lstm_with_unstack\n",
      "INFO:btb.session:Generating new proposal configuration for lstm_with_unstack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'be1a837b1ae453865f0cfb43dc358d40',\n",
       " 'name': 'lstm_with_unstack',\n",
       " 'config': {('sklearn.impute.SimpleImputer#1', 'strategy'): 'constant',\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 102,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1',\n",
       "   'dropout_1_rate'): 0.29143210730762764,\n",
       "  ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 425},\n",
       " 'score': 0.6567251461988304}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6567251461988304"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn.impute.SimpleImputer#1', 'strategy'): 'constant',\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'lstm_1_units'): 102,\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1',\n",
       "  'dropout_1_rate'): 0.29143210730762764,\n",
       " ('keras.Sequential.LSTMTimeSeriesClassifier#1', 'dense_1_units'): 425}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fitting the pipeline\n",
    "\n",
    "Once we are satisfied with the obtained cross validation score, we can proceed to call\n",
    "the `fit` method passing again the same data elements.\n",
    "\n",
    "This will fit the pipeline with all the training data available using the best hyperparameters\n",
    "found during the tuning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train, readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use the fitted pipeline\n",
    "\n",
    "After fitting the pipeline, we are ready to make predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(test, readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate its prediction performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test['target'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save and load the pipeline\n",
    "\n",
    "Since the tuning and fitting process takes time to execute and requires a lot of data, you\n",
    "will probably want to save a fitted instance and load it later to analyze new signals\n",
    "instead of fitting pipelines over and over again.\n",
    "\n",
    "This can be done by using the `save` and `load` methods from the `DracoPipeline`.\n",
    "\n",
    "In order to save an instance, call its `save` method passing it the path and filename\n",
    "where the model should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'my_pipeline.pkl'\n",
    "\n",
    "pipeline.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipeline is saved, it can be loaded back as a new `DracoPipeline` by using the\n",
    "`DracoPipeline.load` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = DracoPipeline.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, it can be directly used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = new_pipeline.predict(test, readings)\n",
    "predictions[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
